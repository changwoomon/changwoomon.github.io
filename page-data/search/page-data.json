{"componentChunkName":"component---src-pages-search-jsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"nodes":[{"excerpt":"TabNet 1. Abstract Sequential attention을 사용해서 각각의 decision step마다 여러 feature들 중에 중요한 feature들만 고름 tabular data의 self-supervised learning도 가능함 (label이 안되어있는..) 2. Related work 1. Feature selection glo…","fields":{"slug":"/TabNet/"},"frontmatter":{"date":"June 08, 2021","title":"TabNet: Attentive Interpretable Tabular Learning","tags":["Paper Review","Tabular Data","TabNet"]},"rawMarkdownBody":"\n## TabNet\n\n<img src=\"tabnet.PNG\">\n\n## 1. Abstract\n\n- Sequential attention을 사용해서 각각의 decision step마다 여러 feature들 중에 중요한 feature들만 고름\n- tabular data의 self-supervised learning도 가능함 (label이 안되어있는..)\n\n## 2. Related work\n\n### 1. Feature selection\n\n- global methods: feature importance를 기반으로 하여 feature selection\n- Instance-wise feature selection: response variable과 선택된 feature들간의 공통 정보를 최대화 하기 위해 explainer model을 사용해서 feature를 individually하게 뽑음\n- TabNet: soft feature selection with controllable sparsity in end-to-end learning  \n  → 단일 모델이 feature selection을 하고 output mapping까지 하는 구조\n\n### 2. Tree-based learning\n\n- tabular data를 위해 많이 사용\n- variance를 줄이기 위해 앙상블 기법을 사용  \n  → random forests, XGBoost, LightGBM 등이 있음\n- 딥러닝이 feature selecting property를 retrainig 시키면 성능이 더 오를 수 있다고 주장\n\n### 3. Integration of DNNs into DTs\n\n### 4. Self-supervised learning\n\n<img src=\"self-supervised learning.png\">\n\n- small data에서 unsupervised representation learning이 성능을 향상시킴을 보임\n- 최근 연구에서는 text와 image에서 큰 성능 향상의 폭을 보임\n  - unsupervised learning과 딥러닝에서 현명한 masking을 통해서 학습을 시키면 좀 더 오름\n\n## 3. Unsupervised pre-training vs Supervised fine-tuning\n\n<img src=\"self-supervised learning.png\">\n\n- Unsupervised Pre-training은 Mask를 씌우고 Mask를 씌운 부분을 맞추는 방법\n    - Label이 따로 필요 없음\n    - 엄청난 loss...\n- Supervised fine-tuning은 다 채워진 tabular data를 가지고 Decision making을 하는 방법\n\n## 4. Tabnet 특징\n\n1. Data에서 Sparse instance-wise feature selection을 사용\n  - salient features(두드러진 feature)들을 선택(selection)하는 것은 높은 성능을 내는데 중요한 요소(특히 dataset이 작을 때)\n  - 따라서 dataset에서 subset을 만들어 determine(결정)하도록 재구성함\n\n  <img src=\"feature_subset.PNG\">\n\n  - 위의 표와 같이 feature에 따른 subset을 만든 것이 Syn1 ~ Syn6 까지임\n  - 여기서 Syn1 ~ Syn3까지의 값은 feature들끼리 독립적인 feature들을 사용\n    - 이렇게 사용하면 global feature (성능이 가장 잘 나오는 이상적인 feature)에 가까워짐\n  - 하지만 Syn4 ~ Syn6까지는 feature들끼리의 종속성이 존재함\n    - instance끼리의 wise한 feature들\n    - 이렇게 사용하면 global selection이 suboptimal로 선택되면서 성능이 낮아질 수 있음\n  - 하지만 Tabnet은 instance-wise feature들을 sparse하게 사용하면서 global feature에 가까워지게 만들어줌\n\n2. Sequential한 multi-step architecture을 가지고 있음\n\n- 각 step들은 선택된 feature들을 가지고 decision을 내리는데 도움을 줌\n\n3. feature 선택에 있어 non-linear한 processing을 사용하면서 learning capacity를 향상시킴\n\n## 5. Tabnet 전체 Architecture\n\n<img src=\"tabnet_encoder.PNG\">\n\n<img src=\"tabnet_decoder.PNG\">\n\n- 전체적으로는 Tabnet의 Encoder 부분과 Decoder 부분으로 구성됨\n- Encoder 부분은 Sequential한 multi-setp processing ($$N_{steps}$$ decision steps로 구성됨)\n- Decoder는 self-supervised learning을 할 때만 사용함\n\n## 6. Feature selection\n\n<img src=\"learnable_mask.png\">\n\n- Learnable Mask $$M[i] \\in R^{B \\times D}$$를 사용\n    - salient feature들을 selection 하기 위해 사용함\n\n- **Attentive transformer 사용**\n\n  <img src=\"attentive_transformer.PNG\">\n\n  - 이전 단계에서 처리된 features들을 사용하여 mask를 얻는 방법\n  - $$M[i] = sparsemax(P[i-1] \\cdot h_{i}(a[i-1]))$$\n    - $$a[i-1]$$: 이전 단계에서 처리된 feature\n    - $$h_{i}$$: trainable function\n      - FC layer와 BN을 의미함\n    - $$P[i]$$: prior scale term\n      - 특정한 feature가 이전에 얼마나 사용되었는지를 나타냄\n      - $$P[i] = \\prod^{i}_{j=1} ( \\gamma - M[j] )$$\n        - $$\\gamma$$는 relaxation parameter\n          - $$\\gamma = 1$$일 때, feature가 한 decision step에서 한개만 사용하도록 함\n          - $$\\gamma$$가 증가하면 여러 decision step에서 feature들을 사용할 수 있음\n        - $$P[0]$$이면 $$1^{B \\times D}$$로 초기화 (모두 $$1$$로 초기화)\n          - 1이면 feature를 사용한다는 의미이므로, feature를 사용하지 않을 때 $$P[0]$$을 $$0$$으로 만들어줌\n\n## 7. Feature processing\n\n<img src=\"feature_processing.PNG\">\n\n- **Feature transformer 사용**\n\n  <img src=\"feature_transformer.PNG\">\n\n  - 대용량을 처리할 때도 robust한 learning을 만들기 위해서는, feature transformer는 `모든 decision step에서 공유되는 layer`와 `decision step-dependents layer`로 구성\n    - `모든 decision step에서 공유되는 layer`를 쓰는 이유는 같은 feature들 모두 다른 decision step의 input으로 들어가기 때문\n    - `decision-step-dependents layer`는 해당 decision일 때만 사용하는 feature들을 processing하는 부분\n  - 위 사진에서는 다음과 같이 구성됨\n    - 두 개의 shared layer\n    - 두 개의 decision step-dependent layers\n  - FC → BN → GLU로 연결\n    - 밑에 있는 화살표는 normalized residual connection\n    - Residual connection을 $$\\sqrt{0.5}$$로 정규화하는 이유는 network 전체의 분산이 크게 변화지 않게 함으로써 학습 안정화에 도움이 됨 (Gehring et al. 2017)\n  - 빠른 training을 위해 BN과 함께 large batch size를 사용해도 됨\n    - ghost BN..?\n  - Aggregation\n    - 모든 decision을 embedding $$d[i]$$\n    - $$d_{out} = \\sum^{N_{steps}}_{i=1} RELU(d[i])$$\n    - 이후, 마지막 linear를 태움: $$W_{final} d_{out}$$\n\n- decision step의 output을 split함\n\n## 8. Interpretability (해석 가능성)\n\n- tabnet의 feature selection mask는 선택된 feature에서 강조표시를 할 수 있음\n  - 일단, $$M_{b,j}[i] = 0$$이면, decision에 참여할 권한 없음\n  - $$M_{b,j}[i]$$ 계수는 feature importance를 나타내는 $$f_{b,j}$$라고 볼 수 있음.\n    ($$f_{i}$$가 linear function일 때)\n    - 그렇지만 각각의 decision step이 non-linear하다고 하더라도, output을 linear하게 합치면 되기 때문에 상관없음\n  - 서로 다른 단계에 있는 mask를 합치려면, decision의 각 단계에서 상대적 중요도를 평가할 수 있는 계수가 필요\n    - 논문에서는 $$\\eta b[i] = \\sum^{N_{d}}_{c=1} RELU(d_{b,c}[i])$$\n      - 즉, $$i^{th}$$번째 decision과 $$b^{th}$$의 sample들을 aggregate한 decision\n    - 위 식을 사용해서 aggregate feature importance mask를 찾는 방법은 다음과 같음\n      - $$M_{agg-b,j} = \\frac {\\sum^{N_{steps}}_{i=1} \\eta b[i]M_{b,j}[i]} {\\sum^{D}_{j=1} \\sum^{N_{steps}}_{i=1} \\eta b[i] M_{b,j}[i]}$$\n\n## 9. self-supervised learning\n\n<img src=\"tabnet_decoder.PNG\">\n\n- Self-supervised learning을 하기 위해 Decoder를 사용\n- Decoder는 feature transformers, FC를 사용함\n- mask를 씌운 부분을 맞추는 것이기 때문에 binary mask인 $$S \\in \\{0,1\\}^{B \\times D}$$를 사용\n- Tabnet encoder에는 $$(1 - S) \\cdot \\hat{f}$$를 input으로 넣음  \n  Tabnet decoder는 reconstructed featres인 $$S \\cdot \\hat{f}$$를 출력함  \n- Reconstruction loss는 다음과 같이 계산됨\n\n<img src=\"reconstruction_loss.png\">\n\n- We sample $$S_{b,j}$$ independently from a **Bernoulli distribution** with parameter $$p_{s}$$, at each iteration.\n\n---\n\n## 결과\n\n- Regression과 Classification task를 수행할 수 있음\n- Forest Cover Type Dataset에서 높은 accuracy를 보여줌\n\n<img src=\"result.png\">\n\n<img src=\"result2.png\">\n\n- Pocker Hand dataset에서도 좋은 성능을 보여줌\n\n<img src=\"result3.png\">\n\n<img src=\"result4.png\">\n\n- Self-supervised learning에서 Dataset size가 크고, pre-training을 함께 진행했을 때 좋은 성능이 나오게됨\n\n<img src=\"result5.png\">\n\n## Hyperparameter 설정 방법\n\n$$N_d, N_a = \\{8, 16, 24, 32, 64, 128\\}$$  \n$$N_{steps} = \\{3, 4, 5, 6, 7, 8, 9, 10\\}$$  \n$$\\gamma = \\{1.0, .12, 1.5, 2.0\\}$$  \n$$\\lambda_{sparse} = \\{0, 0.000001, 0.0001, 0.001, 0.01, 0.1\\}$$  \n$$B = \\{256, 512, 1024, 2048, 4096, 8192, 16384, 32768\\}$$  \n$$B_V = \\{256, 512, 1024, 2048, 4096\\}$$  \n$$lr = \\{0.005, 0.01, 0:02, 0.025\\}$$  \n$$decay \\ rate = \\{0.4, 0.8, 0.9, 0.95\\}$$  \n\n- **Guidelines for hyperparameters**\n  - $$N_{steps}$$는 [3, 10] 사이가 optimal하다.\n    - 너무 높은 $$N_{steps}$$를 사용하면 overfitting의 문제가 생길 수 있다\n  - $$N_d, N_a$$의 설정 문제는 performance와 complexity의 trade-off 문제를 겪을 수 있다.\n    - 따라서 $$N_a = N_d$$가 가장 이상적인 choice이다.\n  - $$\\gamma$$는 Tabnet의 hyperparameter에서 높은 성능을 낼 수 있는 중요한 역할\n    - 대부분 larger $$N_{steps}$$를 사용하면 larger $$\\gamma$$를 사용해야한다.\n  - larger batch size를 사용하는 것이 이득이다.\n  - large learning rate를 쓰는 것이 중요하다.\n    - 어차피 decay될 것\n\n---\n\n# 평가\n\n- tabular data를 처리할 수 있는 딥러닝\n- unsupervised 방식도 가능함\n\n---\n\n## 참고 자료\n\n- 논문: [TabNet: Attentive Interpretable Tabular Learning](https://arxiv.org/abs/1908.07442)\n- GitHub: [TabNet](https://github.com/dreamquark-ai/tabnet)\n"},{"excerpt":"Transformer-DST 1. Key Idea 이전 논문들에서는 Encoder에서 BERT를 사용하지만, Value Generation부분에서는 RNN Decoder를 사용하는 아이러니.. Purely Transformer-based framework를 사용\n즉, Single BERT가 Encoder와 Decoder 모두에서 work\n→ 이렇게 하면 …","fields":{"slug":"/Transformer-DST/"},"frontmatter":{"date":"May 12, 2021","title":"Jointly Optimizing State Operation Prediction and Value Generation for Dialogue State Tracking","tags":["Paper Review","DST","Dialogue State Tracking","Transformer-DST"]},"rawMarkdownBody":"\n## Transformer-DST\n\n## 1. Key Idea\n\n- 이전 논문들에서는 Encoder에서 BERT를 사용하지만, Value Generation부분에서는 RNN Decoder를 사용하는 아이러니..\n- Purely Transformer-based framework를 사용\n즉, Single BERT가 **Encoder와 Decoder 모두**에서 work\n→ 이렇게 하면 prediction objective와 value generation objective가 BERT 하나만 optimize하게 됨\n- Encoder(BERT)에서 사용한 hidden states 값을 Decoder(BERT)에서 Re-use가 가능해짐\n\n## 2. Input\n\n- Input으로는 SOM-DST와 같은 구조를 지님\n- 아래 그림과 같이 **D1, D2, S1을 INPUT**으로 넣고, **OUTPUT으로 S2**를 출력\n\n<img src=\"input.PNG\" height=150>\n\n- $$D_{t-1}, D_{t}, S_{t-1}$$을 INPUT으로 $$S_{t}$$를 PREDICT\n- $$D_{t}$$ : t번째 dialogue turn의 (System utterance, User response) pair\n- $$S_{t}$$ : $$(d_{j}, s_{j}, v_{j}) | 1<=j<=J$$\n\n여기서 $$d$$는 domain, $$s$$는 slot, $$v$$는 value를 나타냄\n\n만약, 아무 정보도 없을시 $$(d_{j}, s_{j})$$로 나타내고, $$v_{j}$$는 NULL\n\n## 3. Overview\n\n- 왼쪽은 Transformer Encoder, 오른쪽은 Transformer Decoder\n- Encoder (왼쪽)에서 $$h_{sl}^{L}$$ (hidden state)를 뽑아내고, Decoder (오른쪽)에서 Re-use하는 방법으로 사용됨\n- Decoder (오른쪽)은 left-to-right attention (왼쪽에서 오른쪽으로 차례로 출력하는 language model, 즉 왼쪽 출력값이 오른쪽 입력)\n\n<img src=\"overview.PNG\">\n\n## 4. Encoder\n\n<img src=\"encoder.PNG\">\n\n- Encoder의 Input은 $$D_{t-1}, D_{t}, S_{t-1}$$ 3가지가 들어감\n    - $$D_{t}$$는 t번째 turn의 ( System Utterance, User Resposne ) pair\n    - $$S_{t-1}$$은 $$(d_{j}, s_{j}, v_{j}) | 1<= j <= J$$\n\n### 4-1) Encoder Input\n\n<img src=\"encoder_input.PNG\">\n\n- $$[SLOT] \\bigoplus d_{j} \\bigoplus - \\bigoplus s_{j} \\bigoplus - \\bigoplus v_{j}$$ 으로 구성\n    - $$\\bigoplus$$는 concat을 나타냄\n    - 총 $$J$$개의 domain-slot에 대해서 만들어줌\n    - $$[SLOT] \\bigoplus d_{j} \\bigoplus - \\bigoplus s_{j} \\bigoplus - \\bigoplus v_{j}$$  * J번\n- $$[SLOT]$$은 Transformer block을 통과한 후, $$X^{l}_{sl_{j}}$$ 형태로 출력되며, Prediction (CARRYOVER, ..., UPDATE 등)으로 사용됨\n\n### 4-2) Multi-head self-attention\n\n<img src=\"multi-head.png\">\n\n- Multi-head Self-attention 매카니즘 사용\n\n<img src=\"multi-head2.png\">\n\n- 여기서 $$M^{x}$$ : self-attention mask matrix\n    - $$M^{x} \\in R^{|x| \\times |x|}$$\n    - $$M^{x}_{ij} \\in \\{0, - \\infty \\}$$\n    - $$M^{x}_{ij} = 0$$이면 i-th position이 j-th position에 attend하다는 의미\n    - $$M^{x}_{ij} = -\\infty$$이면 i-th position과 j-th position을 prevents하겠다는 의미\n\n### 4-3) Encoder Output\n\n$$X^{L} = [x^{L}_{cls}, x^{L}_{1}, ..., x^L_{sl_{1}}, ..., x^{L}_{sl_{J}},...]$$\n\n### 4-4) Encoder Objective\n\n- Encoder outputs $$x^{L}_{sl_{j}}$$에서 $$[SLOT]$$칸에 해당하는 값을 확인\n- CARRYOVER, DELETE, DONTCARE, UPDATE\n- UPDATE의 경우에만 decoder generater에서 사용함\n\n## 5. Decoder (Slot Value Generation)\n\n<img src=\"decoder.PNG\">\n\n- Left-to-right self-attention을 사용함\n- Encoder에서 도출해낸 hidden states를 decoder에서 reuse\n- Resue의 의미는 hidden state를 decoder에서 다시 한번 계산할 필요가 없어진다는 의미를 갖음.\n\n### 5-1) Decoder Input\n\n<img src=\"decoder_input.PNG\">\n\n- Encoder (reuse)\n    - 왼쪽의 $$D_{t}$$와 $$[SLOT]$$은 Encoder 부분을 나타냄\n    - 현재 turn의 $$D_{t}$$의 hidden state vector를 사용함\n    - $$[SLOT]$$ 중 UPDATE로 prediction이 된 hidden state vector만 사용함\n- Decoder\n    - $$[BOS]$$는 String의 시작\n    - $$w^{v_{j}}_1, w^{v_{j}}_2$$는 decoder의 output을 다시 input으로 가지고 와서 사용 (left-to-right self-attention)\n\n### 5-2) Left-to-right self-attention\n\n<img src=\"left-to-right.png\">\n\n<img src=\"left-to-right2.png\">\n\n- 일반 Multi-head attention하고 비슷\n- $$\\hat{X}$$ : re-used된 encoder hidden states\n- $$Y$$ : Decoder hidden states\n- $$\\hat{X}$$와 $$Y$$를 concat해서 사용\n- 만약 $$j \\leq i$$일때,  $$M^{y}_{ij} = 0$$ 으로 사용 (left-to-right attention)\n\n### 5-3) Decoder Objective\n\n- **Generated slot value loss**와 **ground-truth slot value**를 비교해서  Loss를 산출\n- Teacher Forcing을 모든 time에서 사용\n\n# 결과\n\n- MutliWOZ 2.0과 MultiWOZ 2.1에서 제출 당시 SOTA\n\n<img src=\"result.png\">\n\n- 각각의 Domain의 Joint goal Accuracy를 비교\n    - 신기한 점은 Taxi 빼고 (다른 모델보다) 높은 성능을 보임\n    - 이유를 찾아보니 Taxi의 경우 Train과의 co-occurrence relations가 있음\n    - 하지만 Ours에는 이러한 점을 해결하려고 하지는 않았음\n\n<img src=\"result2.png\">\n\n- 시간의 경우 SOM-DST보다는 Inference time이 오래걸림\n\n<img src=\"result3.png\">\n\n- Reuse를 사용했을 경우에도 여러가지 방법을 시도해보았고, $$D_{t} + [SLOT]$$을 사용했을 때 Joint Accuracy에서 좋은 성능을 보였음\n\n<img src=\"result4.png\">\n\n---\n\n## 참고 자료\n\n- 논문: [Jointly Optimizing State Operation Prediction and Value Generation for Dialogue State Tracking](https://arxiv.org/abs/2010.14061)\n- GitHub: [Transformer-DST](https://github.com/zengyan-97/Transformer-DST)\n"},{"excerpt":"SOM-DST SOM-DST 기존 모델의 문제점 Ontology-based DST 실제 시나리오에 잘 대응하지 못함 unseen value를 처리할 수 없음 ontology가 많으면 처리 시간이 오래 걸림 Open-vocab-based DST (TRADE) turn마다 slot의 모든 value를 생성해야해서 비효율적임 Definition : turn :…","fields":{"slug":"/SOM-DST/"},"frontmatter":{"date":"May 10, 2021","title":"Efficient Dialogue State Tracking by Selectively Overwriting Memory","tags":["Paper Review","DST","Dialogue State Tracking","SOM-DST"]},"rawMarkdownBody":"\n## SOM-DST\n\n![SOM-DST](https://github.com/clovaai/som-dst/raw/master/img/overview6.png)\n\n## 기존 모델의 문제점\n\n### Ontology-based DST\n\n- 실제 시나리오에 잘 대응하지 못함\n- unseen value를 처리할 수 없음\n- ontology가 많으면 처리 시간이 오래 걸림\n\n### Open-vocab-based DST (TRADE)\n\n- turn마다 slot의 모든 value를 생성해야해서 비효율적임\n\n---\n\n## Definition\n\n$$t$$: turn\n\n$$S^j$$: slot\n\n$$V^j_t$$: corresponding slot value\n\n$$J$$: total number of such slots\n\n$$r^j_t\\in O = \\left\\{\\rm\\textbf{CARRYOVER, DELETE, DONTCARE, UPDATE}\\right\\}$$\n\n$$A_t$$: System response\n\n$$U_t$$: User utterance\n\n---\n\n## State Operation Predictor (Encoder)\n\nEncoder 모델로 **pretrained BERT encoder** 사용\n\n### <span style=\"background-color:#fcffb0\">Encoder Input을 만들기 위한 준비물</span>\n\n$$D_t = A_t ⊕ ; ⊕ U_t ⊕ [SEP]$$: dialogue utterances at turn t\n\n- `;` $A_t$와 $U_t$를 구분하기 위한 스페셜 토큰\n- `[SEP]` dialogue turn이 끝났다는 것을 표시하기 위한 스페셜 토큰\n\n$$B_t^j = [SLOT]^j ⊕ S^j ⊕ - ⊕ V_t^j$$ : representation of the j-th slot-value pair\n\n- j-th slot-value pair를 하나의 벡터로 aggregate\n- $$`[SLOT]^j`$$\n\n    [SLOT] 이라는 스페셜 토큰을 사용\n\n    BERT의 [CLS] 토큰과 같은 역할\n\n- $$`V_t^j`$$\n\n    <img src=\"V_t^j.PNG\" height=150>\n\n$$B_t = B_t^1 ⊕ ... ⊕ B_t^J$$ : representation of the dialogue state at turn t\n\n### Encoder Input\n```\n$$X_t = [CLS] ⊕ D_{t-1} ⊕D_t ⊕ B_{t-1}$$\n\nsegment id:        0       1         1\n```\n⇒ **Input : Sum($X_t$ embedding, segment id embedding, positional embedding)**\n\ndialogue history로 이전 턴의 dialogue utterances $$D_{t-1}$$을 사용한다.\ndialogue history의 size: 1\n\n모델이 입력으로 들어오는 dialogue 간의 `Markov property`를 가정\n\n이전 turn dialogue state $$B_{t-1}$$은 전체 dialogue history를 압축적으로 표현하는 역할\n\n### Encoder Output\n\n$$H_t \\in \\mathbb R^{\\left|X_t\\right|\\times d}$$ : $$h_t^{\\rm X}$$ $$(t=1...t)$$ 까지 집합\n\n$$h_t^{[CLS]}, h_t^{[SLOT]^j} \\in \\mathrm R^d$$\n\n- $$[CLS], [SLOT]^j$$에 대응하는 output\n\n$$h_t^X = tanh(W_{pool} h_t^{[CLS]})$$\n\n- $$h_t^X$$: 전체 input $$X_t$$를 sequence로 aggregate\n- $$W_{pool} \\in \\mathbb R^{d\\times d}$$: feed-forward layer with a learnable parameter\n\n### State Operation Prediction\n\n$$P^j_{opr, t} = softmax(W_{opr} h_t^{[SLOT]^j})$$\n\n- $$W_{opr} \\in \\mathbb R^{\\left| O\\right|\\times d}$$ : learnable parameter\n- $$P_{opr, t}^j \\in \\mathbb R^{\\left| O\\right|}$$ : j-th slot의 turn t에서의 연산에 대한 확률 분포\n- SOM-DST에서는 $$\\left| O\\right| = 4$$,\n\n    $$O = \\left\\{\\rm{CARRYOVER, DELETE, DONTCARE, UPDATE}\\right\\}$$\n\n→ $$r_t^j = argmax(P_{opr, t}^j)$$\n\n→ slot의 Operation의 결과가 `UPDATE` 일 때 slot value를 generation\n\n- Encoder에서 나온 Operation의 결과가 `Update`인 경우를 집합으로 표현하면\n\n    $$\\mathbb{U}_t = \\left\\{j|r_t^j = \\rm{UPDATE}\\right\\}$$, and its size as $$J_t^\\prime = \\left| \\mathbb{U}_t\\right|$$\n\n    Recab for V\n\n    <img src=\"V_t^j.PNG\" height=150>\n\n---\n\n## Slot Value Generator (Decoder)\n\n- Encoder에서 나온 Operation의 결과가 `Update` 인 경우 해당 slot의 value를 예측\n- SOM-DST의 generator는 value를 $$J$$개가 아닌 $$J^\\prime_t$$개의 slot에 대해서만 만들어준다.\n\n    대부분의 경우에서 $$J^\\prime_t \\ll J$$이기 때문에 더 효율적이라고 주장\n\n- Decoder 모델로 **GRU** 사용\n    - 입력으로 word embedding vector $$e_t^{j,k}$$를 받으면서 **GRU**의 hidden state vector $$g_t^{j, k}$$를 recurrent하게 업데이트\n    - $$g_t^{j, 0} = h_t^{\\rm x}$$, $$e_t^{j,0} = h_t^{[slot]j}$$: **GRU**에 들어가는 초기값\n    - $$g_t^{j, k} = GRU(g_t^{j, k-1}, e_t^{j,k})$$\n    - $$e_t^{j,k}$$가 [EOS] 토큰이 나올때까지 진행\n    - hidden state $$g_t^{j, k}$$는 k-th decoding step을 거치면서 vocabulary 와 user utterance의 단어에 대한 확률 분포로 변함\n\n        $$P^{j, k}_{vcb, t} = softmax(Eg^{j, k}_t) \\in \\mathbb R^{d_{vcb}}$$\n\n        - $$E \\in \\mathbb R^{d_{vcb}\\times d}$$: Encoder와 Decoder가 서로 공유하는 word embedding matrix\n            - $$d_{vcb}$$: vocabulary size\n\n        $$P^{j, k}_{ctx, t} = softmax(H_t g_t^{j, k}) \\in \\mathbb R^{\\left|X_t\\right|}$$\n\n        - user utterance의 단어에 대한 확률 분포\n\n        $$P^{j, k}_{val, t} = \\alpha P^{j, k}_{vcb, t} + (1-\\alpha) P^{j, k}_{ctx, t}$$: final output distribution\n\n        - $$\\alpha = sigmoid(W_1 \\left[g^{j, k}_t ; e^{j, k}_t ; c^{j, k}_t\\right])$$\n            - $$W_1 \\in \\mathbb R^{1\\times (3d)}$$: learnable parameter\n            - $$c^{j, k}_t = P^{j, k}_{ctx, t} H_t \\in \\mathbb R^d$$: context vector\n\n---\n\n## Objective Function\n\n### State operation predictor\n\n**Main Task**\n\nstate operation classification\n\n**Auxiliary Task**\n\ndomain classification\n\nstate operation classification 외에도 domain classification을 보조 task로 사용하여 모델이 dialogue turn 간의 slot operation과 domain transition의 상관 관계를 학습하도록 함\n\n$$P_{dom, t} = softmax(W_{dom} h_t^{\\rm X})$$\n\n- $$W_{dom} \\in \\mathbb R^{d_{dom}\\times d}$$: learnable parameter\n- $$P_{dom, t} \\in \\mathbb R^{d_{dom}}$$: turn t에서 domain에 대한 확률 분포\n    - $$d_{dom}$$: # of domains defined in the dataset\n\n**Average of the negative log-likelihood**\n\n$$L_{opr, t} = -\\frac{1}{J}\\sum_{j=1}^{J}(Y_{opr, t}^j)^\\top log(P^j_{opr, t})$$\n\n$$L_{dom, t} = -(Y_{dom, t})^\\top log(P_{dom, t})$$\n\n- $$Y_{dom, t} \\in \\mathbb R^{d_{dom}}$$: one-hot vector for the ground truth domain\n- $$Y^j_{opr, t} \\in \\mathbb R^{\\left| O\\right|}$$: one-hot vector for the ground truth operation for the j-th slot\n\n### Slot value generator\n\n**Average of the negative log-likelihood**\n\n$$L_{svg, t} = -\\frac{1}{\\left|\\mathbb U_t\\right|}\\sum_{j\\in\\mathbb U_t}^{}\\left[\\frac{1}{K^j_t}\\sum_{k=1}^{K^j_t}(Y_{val, t}^{j, k})^{\\top}log(P^{j, k}_{val, t})\\right]$$\n\n- $$K_t^j$$: # of tokens of the ground truth value that needs to be generated for the j-th slot\n- $$Y_{val, t}^{j, k} \\in \\mathbb R^{d_{vcb}}$$: one-hot vector for the ground truth token that needs to be generated for the j-th slot at the k-th decoding step\n\n### Final Loss\n\nto minimized $$L_{joint, t} = L_{opr, t} + L_{dom, t} + L_{svg, t}$$\n\n---\n\n## Experimental Setup\n\n### Datasets\n\nMultiWOZ 2.0 and MultiWOZ 2.1\n\n### Training\n\n- Encoder : Bert-base-uncased\n- Decoder : GRU\n- Hidden size : 768\n- Optimizer : BertAdam\n- Encoder LR and warmup : 4e-5, 0.1\n- Decoder LR and warmup : 1e-4, 0.1\n- Batch size : 32\n- Dropout : 0.1\n- Word Dropout 적용, 0.1확률로 word 를 [UNK] 로 바꿈\n- Input max length : 256\n- Training Epoch : 30\n\n---\n\n## 결과\n\n### Joint Goal Accuracy\n\n<img src=\"joint_goal_accuracy.PNG\" height=400>\n\n> † indicates the case where BERT-large is used for our model\n\n### Domain-specific Accuracy\n\n<img src=\"domain-specific_accuracy.PNG\" height=450>\n\n### Latency\n\n<img src=\"latency.PNG\" height=150>\n\n---\n\n## 평가\n\n- JGA, Domain-specific Accuracy 에서 SOTA 혹은 비슷한 수준의 성능을 보여줌\n- inferecnce 타임이 매우 짧음에도 불구하고 좋은 성능을 보여줌\n\n---\n\n## 참고 자료\n\n- 논문: [Efficient Dialogue State Tracking by Selectively Overwriting Memory](https://arxiv.org/abs/1911.03906)\n- 영상: [[Paper Review] SOM-DST : Efficient Dialogue State Tracking by Selectively Overwriting Memory - KoreaUniv DSBA](https://www.youtube.com/watch?v=7Nwe2BBUZsw)\n- GitHub: [SOM-DST](https://github.com/clovaai/som-dst)\n"},{"excerpt":"CHAN-DST slot imbalance 문제를 해결하고자 adaptive objective를 도입 a contextual hierarchical attention network (CHAN)를 사용: dislogue history에서 relevant context를 찾기 위함 → 각 턴의 발화로부터 word-level 관련 정보 검색 → contextu…","fields":{"slug":"/CHAN-DST/"},"frontmatter":{"date":"May 07, 2021","title":"A Contextual Hierarchical Attention Network with Adaptive Objective for Dialogue State Tracking","tags":["Paper Review","DST","Dialogue State Tracking","CHAN-DST"]},"rawMarkdownBody":"\n## CHAN-DST\n\n- slot imbalance 문제를 해결하고자 adaptive objective를 도입\n- a contextual hierarchical attention network (CHAN)를 사용: dislogue history에서 relevant context를 찾기 위함  \n  → 각 턴의 발화로부터 word-level 관련 정보 검색  \n  → contextual representation으로 encode  \n  → 모든 context표현을 turn-level관련 정보로 집계한 후 word-level 정보와 합친 output 생성  \n- state transition prediction task\n\n---\n\n## Definition\n\n- $$T$$: turn\n- $$U_t$$: user utterance of turn t\n- $$R_t$$: system response of turn t\n- $$X$$: $$\\left\\{(U_1, R_1), ... , (U_T, R_T)\\right\\}$$\n- $$B_t$$: $$\\left\\{(s, v_t), s \\in S\\right\\}$$\n- $$S$$: set of slots\n- $$v_t$$: corresponding value of the slot $$s$$\n- slot: concatenation of a domain name and a slot name\n\n---\n\n## Contextual Hierarchical Attention Network\n\n<img src=\"structure.png\">\n\n### 1. Sentence Encoder\n\n<img src=\"sentence_encoder.png\">\n\n`utterance encoder`\n\n- BERT special token 사용  \n  → [CLS] : 문장의 representation들을 합치기위해 사용 (to aggregate the whole representation of a sentence)  \n  → [SEP] : 문장의 끝을 나타내기위해 사용.  \n- $$U_t = \\left\\{w_1^u, ..., w_l^u\\right\\}$$ (user utterance)  \n  $$R_t = \\left\\{w_1^r, ..., w_{l'}^r\\right\\}$$ (system response)  \n  $$t$$: dialogue turn  \n- $$h_t = BERT_{finetune}([R_t;U_t])$$  \n  ($$h_t$$: contextual word representations)  \n- 여기서 BERT finetune은 training도중 finetuning이 될것을 의미.\n\n`slot-value encoder`\n\n- $$BERT_{fixed}$$는 contextual semantics vectors로 encode해준다.\n- utterance encode할때와 다른 점은 [CLS] 토큰의 output vector를 전체 문장 representation할때 사용한다. (to obtain the whole sentence representation)\n- $$h_s = BERT_{fixed}(s)$$  \n  $$h_t^v = BERT_{fixed}(v_t)$$  \n- $$BERT_{fixed}$$는 training 도중 고정되어있다. 그래서 우리 모델은 unseen slots and values에 대해서 original BERT representation로 확장해서 보는게 가능하다.\n\n### 2. Slot-Word Attention\n\n<img src=\"slot-word_attention.png\">\n\n- slot-word attention은 multi-head attention을 사용한다.\n- $$c_{s,t}^{word} = MultiHead(h^s, h_t, h_t)$$\n\n### 3. Context Encoder\n\n<img src=\"context_encoder.png\">\n\n- context encoder : unidirectional transformer encoder\n- {1, ..., t} 턴에서 추출 된 word-level slot-related 정보의 contextual relevance를 모델링하기 위한 것.\n- $$N$$개의 idenctical한 layer가 있다.\n  - 각 layer는 2개의 sub-layer를 가지고 있다.\n  - 첫번째 sub-layer: masked multi-head self-attention(Q = K = V)\n  - 두번째 sub-layer: position-wise fully connected feed-forward network(FFN) (two linear transformations, RELU activation으로 구성)\n  - $$FFN(x) = max(0, xW_1 + b_1)W_2 + b_2$$\n- $$m^n = FFN(MultiHead(m^{n-1}, m^{n-1}, m^{n-1}))$$  \n  $$m^0 = [c_{s,1}^{word} + PE(1), ..., c_{s,t}^{word} + PE(t)]$$  \n  $$c_{s,\\leq t}^{ctx} = m^N$$  \n- $$m^n$$: n번째 context encoder레이어의 아웃풋\n  $$PE(.)$$: positional encoding function\n\n### 4. Slot-Turn Attention\n\n<img src=\"slot-turn_attention.png\">\n\n- turn-level relevant information을 contextual representation에서 검출해내기 위해 사용\n- $$c_{s,t}^{turn} = MultiHead(h^s, c_{s,\\leq t}^{ctx},c_{s,\\leq t}^{ctx})$$\n- 이로인해 word-level and turn-level 의 relevant information을 historical dialogues에서 얻어낼 수 있다.\n\n### 5. Global-Local Fusion Gate\n\n<img src=\"global-local-fusion_gate.png\">\n\n- global context와 local utterance의 균형을 맞추기 위해, contextual information과 current turn information의 비율을 조절함.\n- $$c_{s,t}^{word},~~ c_{s,t}^{turn}$$에 따라 global과 local정보가 어떻게 결합되어야할지 알려주는 fusion gate mechanism을 사용\n- $$g_{s,t} = \\sigma(W_g\\bigodot[c_{s,t}^{word};c_{s,t}^{turn}])$$\n- $$c_{s,t}^gate = g_{s,t}\\bigotimes c_{s,t}^{word} + (1-g_{s,t}\\bigotimes c_{s,t}^{turn})$$\n  - $$W_g \\in R^{2d\\times d}$$\n  - $$\\sigma$$: Sigmoid\n  - $$\\bigodot$$, $$\\bigotimes$$\n- $$o_{s,t}$$ = LayerNorm(Linear(Dropout($c_{s,t}^{gate}$)))\n- **value $$v_t$$에 대한 확률분포와 training objective**  \n  $$p(v_t|U_{\\leq t},~R_{\\leq t}, s) = exp(-||o_{s,t} - h_t^v||2)\\over {\\sum{v'\\in V_s}exp(-||o_{s,t}-h_t^{v'}||2)}$$  \n  *$$L{dst}$$* $$= \\sum_{s\\in S}\\sum ^T_{t = 1}-log(p(\\hat v_t|U_{\\leq t},~R_{\\leq t}, s))$$  \n  - $$V_s$$: candidate value set of slot s\n  - $$\\hat v_t \\in V_s$$: ground-truth value of slot s\n\n---\n\n## State Transition Prediction\n\n<img src=\"state_transition_prediction.png\">\n\n- relevant context를 더 잘 포착하기 위해, auxiliary binary classification task사용.\n- $$c_{s,t}^{stp} = tanh(W_c \\odot c_{s,t}^{gate})$$\n- $$p_{s,t}^{stp} = \\sigma (W_p \\odot [c_{s,t}^{stp};c_{s, t-1}^{stp}])$$\n  - $$W_c \\in \\R^{d\\times d}$$\n  - $$W_c \\in \\R^{2d}$$\n  - $$t = 1$$일때는 $$c_{s,t}^{stp}$$와 zero vectors를 concat함.\n- binary CE loss ($$y_{s,t}^{stp}$$: ground-truth transition labels // $$p_{s,t}^{stp}$$: transition probability)\n- $$L_{stp} = \\sum_{s\\in S}\\sum_{t = 1}^T -y_{s,t}^{stp}~.~log(p_{s,t}^{stp})$$\n\n---\n\n## Adaptive Objective\n\n- hard slots와 samples에 관한 optimization을 encourage한다.\n- all slots의 learning을 balancing함.\n- $$acc_s^{val}$$: accuracy of slot s on validation set\n- `slot-level difficulty`\nif $$acc_s^{val} \\leq acc_{s'}^{val}$$;  \n  → slot s 가 slot s'보다 더 어려운 것.  \n  → $$\\alpha$$: slot-level difficulty  \n  - $$\\alpha_s = {1 - acc_s^{val} \\over {\\sum_{s'\\in S} 1-acc_{s'}^{val}}} \\cdot |S|$$\n- `sample-level difficulty`  \n  → Suppose there are two samples $$\\left\\{(U_t, R_t),(s, v_t)\\right\\}$$ and $$\\left\\{(U_{t'}, R_{t'}),(s', v_{t'})\\right\\}$$  \n  → 만약 former confidence 가 latter보다 더 낮다면, 첫번째 sample이 두번째보다 더 어려운 것.  \n  → $$\\beta$$: sample level difficulty  \n  - $$\\beta(s, v_t) = (1 - p(s, v_t))^\\gamma$$\n  - $$p(s,v_t)$$: confidence of sample $$(U_t, R_t),(s, v_t)$$  \n  $$\\gamma$$: hyper-parameter\n- $$L_{adapt}(s,v_t) = -\\alpha_s\\beta(s, v_t)log(p(s, v_t))$$\n- slot s가 평균 slot의 difficulty보다 높다면, $$\\alpha_s$$는 s에 대한 loss를 키울 것이다. 비슷하게, sample의 optimization이 low confidence를 갖고 있다면 loss는 커질것이다.\n\n---\n\n### Optimization\n\n- During joint training, we optimize the sum of these two loss functions as following  \n  $$L_{joint} = L_{dst} + L_{stp}$$  \n- At the fine-tuning phase, we adopt the adaptive objective to fine-tune DST task as following  \n  $$L_{finetune} = \\sum_{s\\in S}\\sum^T_{t=1}L_{adapt(s, \\hat v_t)}$$  \n\n---\n\n## 참고 자료\n\n- 논문: [A Contextual Hierarchical Attention Network with Adaptive Objective for Dialogue State Tracking](https://www.aclweb.org/anthology/2020.acl-main.563.pdf)\n- GitHub: [CHAN-DST](https://github.com/smartyfh/CHAN-DST)\n"},{"excerpt":"TRADE 1. 전체 프로세스 TRADE 대화를 인코더를 통해 인코딩한다. 인코딩된 대화와 슬롯으로 를 만들고, 이를 바탕으로 와 를 생성하여 로 슬롯에 해당하는 value를 찾는다. 대화와 슬롯으로 만들어진 를 사용하여 를 만들고, 를 통해 slot의 value를 사용할지 결정한다. 2. Definition (Terminology) : User Utte…","fields":{"slug":"/TRADE/"},"frontmatter":{"date":"April 30, 2021","title":"Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems","tags":["Paper Review","DST","Dialogue State Tracking","TRADE"]},"rawMarkdownBody":"\n## TRADE\n\n### 1. 전체 프로세스\n\n![TRADE](https://github.com/jasonwu0731/trade-dst/raw/master/plot/model.png)\n\n1. 대화를 인코더를 통해 인코딩한다.\n2. 인코딩된 대화와 슬롯으로 $$h$$를 만들고, 이를 바탕으로 $$p_{value}$$와 $$p_{hist}$$를 생성하여 $$p_{final}$$로 슬롯에 해당하는 value를 찾는다.\n3. 대화와 슬롯으로 만들어진 $$h_{j0}$$를 사용하여 $$p_{hist}$$를 만들고, $$c_{j0}$$를 통해 slot의 value를 사용할지 결정한다.\n\n---\n\n### 2. Definition (Terminology)\n\n- $$U_{T}$$: User Utterence\n- $$R_{T}$$: System Response\n- $$X_t = \\{ (U_{t-l}, R_{t-l}), ... (U_{t}, R_{t})\\}$$:  Utterance-Response pair\n- $$D = \\{ D_{1}, ..., D_{N} \\}$$: Domain\n- $$S = \\{ S_{1}, ..., S_{M} \\}$$: Slot\n- $$Y^{value}_{j}$$: Value\n- $$B = \\{ B_{1}, ..., B_{T} \\}$$: Tuple\n\n### 3. Utterance Encoder\n\n<img src=\"utterance_encoder.png\">\n\n- 논문에서는 **Bi-directional GRU**사용 (어떤 종류의 Encoder로도 대체 가능)\n- Input: $$X_t = \\{ (U_{t-l}, R_{t-l}), ... (U_{t}, R_{t})\\}$$\n  - 슬라이딩 윈도우처럼 $$l$$값에 따라 $$t$$번째 턴에는 $$t-l$$부터 $$t$$까지의 대화쌍을 살펴봄\n    - 베이스라인 코드에서는 $$t$$ 턴에는 처음부터 $$t$$ 턴까지 대화를 모두 봄\n  - 더 구체적으로 말하자면, dialougue history 의 **모든 단어**를 **concatenation** 한 것\n  - $$d_{emb}$$ 차원을 지님\n- $$t$$ 턴까지의 대화쌍에서 토큰들의 관계를 알 수 있다.\n\n### 4. State Generator\n\n<img src=\"state_generator.png\">\n\n- Bi-directional GRU decoder 사용\n- $$t$$ 턴까지의 대화 인코딩 $$h_t$$에 대해 max_length(value 중 가장 토큰을 많이 가진 길이)만큼 디코더로 디코딩 진행\n- Copy mechanism을 통해 input dialougue의 정보를 활용하여 slot value를 generate\n- 처음에는 도메인-슬롯의 임베딩 sum 을 입력으로 넣어주고 이를 통해 value 의 첫 토큰이 나온다.  \n  다음으로는 이 토큰을 입력으로 넣어주고.. 계속하여 알맞는 value 를 뽑아낸다 (서울 + 롯데 + 호텔).  \n  그러다 special token 이 나오면 value 생성을 그만한다.\n- Pointer-Generator 방법 사용\n  - 위에서 생성된 $$h^{dec}_{j0}$$로 $$p_{vocab}$$(대화와 슬롯을 봤을 때 vocab 에서는 어떤 단어와 유사한지), $$p_{hist}$$(대화와 슬롯을 봤을 때 이제까지의 대화 중에서는 어떤 단어와 유사한지)를 구한다.\n  - **Vocab의 분포**와 **dialogue history의 분포**를 하나의 분포로 결합\n\n<img src=\"P_vocab, P_history.png\">\n\n- $$P^{vocab}_{jk}$$는 Utterence Encoder에서 나타나는 (domain, slot) $$j$$번째, $$k$$번째 value 생성 차례의 vocab 확률 분포를 나타냄\n  - 여기서 $$E \\in \\R^{|V| \\times d_{hdd}}$$를 나타내고, Trainable Embedding (vocab 개수 x dimension)\n- $$P^{history}_{jk}$$는 Utterence Encoder에서 나타나는 (domain, slot) $$j$$번째, $$k$$번째 value 생성 차례의 history 확률 분포를 나타냄\n  - 여기서 $$H_{t}$$는 Encode된 dialouge history를 나타냄\n\n<img src=\"P_final.png\">\n\n- $$P^{final}_{jk}$$는 $$P^{vocab}_{jk}$$, $$P^{history}_{jk}$$의 $$P^{gen}_{jk}, 1-P^{gen}_{jk}$$만큼의 확률분포를 곱해서 생성\n\n<img src=\"p_gen.png\">\n\n- $$P^{gen}_{jk}$$는 다음 원소들로 구성됨\n  - $$W_{1}$$: 가중치\n  - $$h^{dec}_{jk}$$: (domain, slot) pair와 Utterance Encoding을 가지고 만들어진 hidden state vector\n  - $$w_{jk}$$: word embedding\n  - $$c_{jk}$$: context vector\n  - ;는 concat을 나타냄\n\n### 5. Slot Gate\n\n<img src=\"slot_gate.png\">\n\n- Slot Generator 에서 생성된 $$h^{dec}_{j0}$$(대화와 슬롯의 관계 정보)를 통해 $$p_{history}$$를 만들고, 이를 사용해 $$c_{j0}$$(Context vecto)를 만들 수 있다. Slot Gate는 Context vector로부터 slot의 존재 여부를 알아내는 역할을 수행\n  - PTR, DONTCARE, NONE 3가지 label로 출력\n  - PTR이 나오면 value를 Generate\n  - DONTCARE, NONE이 나오면 Ignore\n\n<img src=\"G_j.png\">\n\nSlot gate $$G_{j}$$는 다음 원소로 구성됨\n\n- $$W_{g}$$: 가중치\n- $$c_{j0}$$: Context vector(first decoder Hidden state)\n\n### 6. Optimization\n\n<img src=\"optimization.png\">\n\n> 출처 : [https://www.youtube.com/watch?v=nuclwoebdEM](https://www.youtube.com/watch?v=nuclwoebdEM)\n\n- 최종 Loss는 다음으로 구성됨\n\n$$L = \\alpha L_{g} + \\beta L_{v}$$\n\n# 결과\n\n### 1. Few/Zero-shot 실험 셋팅\n\n- Target Domain을 학습 데이터에서 제외\n    - 나머지 Source Domain의 데이터로 학습 후, Target Domain에 대한 성능 측정\n- Few-Shot의 경우 Target Domain에 대한 아래 방법들로 1%의 Training data만 사용하여 학습\n    - Elastic Weight Consolidation (EWC)\n    - Gradient Episodic Memory (GEM)\n    - Naive Fine-tuning (Naive)\n\n<img src=\"few, zero.png\">\n\n### 2. 실험 결과\n\n<img src=\"result.png\">\n\n- **첫번째는 하나의 Domain만 제외(ex. Except Hotel)해서 훈련시킴**\n    - 이후, 제외시킨 Domain (ex. Hotel)의 1% data를 fine-tuning했을 때의 결과\n    - GEM을 사용했을 때 가장 좋은 성능이 나오는 것을 알 수 있음\n\n- **두번째는 하나의 Domain만 훈련시킨 후 (ex. Hotel) 측정하는 방법**\n    - Train, Taxi Domain에서 높은값들이 나오는 이유는 Domain끼리 겹치는 slot이 존재하기 때문\n\n# 평가\n\n- 새로운 domain(unseen domain)에 대해 robust한 모델\n- Pointer-Generator를 사용해 Open-Vocabulary 방법을 사용\n- turn마다 모든 슬롯 $$j$$에 대해 value를 생성하는 점이 비효율적임\n\n---\n\n## 참고 자료\n\n- 논문: [Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems](https://arxiv.org/abs/1905.08743)\n- 영상: [[Paper Review] Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems - KoreaUniv DSBA](https://www.youtube.com/watch?v=nuclwoebdEM)\n- GitHub: [TRADE](https://github.com/jasonwu0731/trade-dst)\n"}]}},"pageContext":{}},"staticQueryHashes":[]}